image: python:3.8

pipelines:
  default:
    - parallel:
      - step:
          name: Test
          caches:
            - pip
          script:
            - if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
            - pip install pytest
            - pytest -v tests/* --junitxml=test-reports/report.xml
      - step:
          name: Lint code
          script:
            # Enforce style consistency across Python projects https://flake8.pycqa.org/en/latest/manpage.html
            - pip install flake8
            - flake8 . --extend-exclude=dist,build --show-source --statistics
      - step:
          script:
            - npm install
            - npm test
            - docker version
          services:
            - docker
            - redis
            - postgres

  branches:
    staging:
      - parallel:
          - step:
              name: Build and Test
              caches:
                - node
              script:
                - npm install
                # CI=true in default variables for Bitbucket Pipelines https://support.atlassian.com/bitbucket-cloud/docs/variables-in-pipelines/
                - npm test
                - npm run build
              artifacts:
                - build/**
          - step:
              name: Security Scan
              script:
                # Run a security scan for sensitive data.
                # See more security tools at https://bitbucket.org/product/features/pipelines/integrations?&category=security
                - pipe: atlassian/git-secrets-scan:0.4.3
      - step:
          name: Deploy to Staging
          deployment: Staging
          trigger: manual
          clone:
            enabled: false
          script:
            # sync your files to S3
            - pipe: atlassian/aws-s3-deploy:0.4.4
              variables:
                AWS_ACCESS_KEY_ID: $AWS_ACCESS_KEY_ID
                AWS_SECRET_ACCESS_KEY: $AWS_SECRET_ACCESS_KEY
                AWS_DEFAULT_REGION: $AWS_DEFAULT_REGION
                S3_BUCKET: 'my-bucket-name'
                LOCAL_PATH: 'build'

            # triggering a distribution invalidation to refresh the CDN caches
#            - pipe: atlassian/aws-cloudfront-invalidate:0.1.1
#              variables:
#                AWS_ACCESS_KEY_ID: $AWS_ACCESS_KEY_ID
#                AWS_SECRET_ACCESS_KEY: $AWS_SECRET_ACCESS_KEY
#                AWS_DEFAULT_REGION: $AWS_DEFAULT_REGION
#                DISTRIBUTION_ID: '123xyz'

definitions:
  services:
    redis:
      image: redis:3.2
      memory: 512
    docker:
      memory: 2048  # reduce memory for docker-in-docker from 1GB to 512MB
    postgres:
      image: postgres
      variables:
        POSTGRES_DB: 'pipelines'
        POSTGRES_USER: 'test_user'
        POSTGRES_PASSWORD: 'test_user_password'